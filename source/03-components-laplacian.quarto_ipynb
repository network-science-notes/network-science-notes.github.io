{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "code-fold: true\n",
        "code-summary: \"Show code\"\n",
        "---\n",
        "\n",
        "\n",
        "# Components and the Graph Laplacian\n",
        "\n",
        "In the last lecture, we discovered that the notion of connectivity could tell us something important about graph structure. \n",
        "\n",
        "## Components\n",
        "\n",
        "Many networks have parts that are disconnected from each other. These parts are called **components**. As we saw in an example from the previous lecture, there is no path between any pair of nodes in different components of a network. In undirected graphs, the definition of connected components is relatively simple. \n",
        "\n",
        "::: {.callout-note icon=false appearance=\"minimal\"}\n",
        "::: {#def-component}\n",
        "\n",
        "## Connected Components in an Undirected Graph\n",
        "\n",
        "Two nodes $i$ and $j$ are **path-connected** if there exists a path between $i$ and $j$. The set $\\{j \\in V : i \\text{ is path-connected to } j\\}$ is called the **connected component** of $i$. A graph is **connected** if it has only one connected component. Otherwise, we say the network is **disconnected**. [For the purposes of this definition, we say that every node $i$ has a zero-length path to itself. It follows that a singleton (a node with no edges attached) is its own connected component.]{.aside}\n",
        "\n",
        ":::\n",
        ":::\n",
        "\n",
        "::: {.callout-important}\n",
        "\n",
        "## Exercise\n",
        "\n",
        "Prove that the relation $~$ defined as $i ~ j$ iff there exists a path between $i$ and $j$ is an equivalence relation. Prove also that the equivalence classes of this relation are exactly the connected components of $G$. \n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "As we saw with degree, the definition of connected components requires a bit more subtlety when we consider directed networks. \n",
        "\n",
        "::: {.callout-note icon=false appearance=\"minimal\"}\n",
        "::: {#def-strongly-weakly-connected}\n",
        "\n",
        "## Strongly and Weakly Connected Components\n",
        "\n",
        "In a directed network, two nodes $i$ and $j$ are **strongly connected** if there exists a path from $i$ to $j$ and a path from $j$ to $i$. Nodes $i$ and $j$ are **weakly connected** if there exists either a path from $i$ to $j$ or from $j$ to $i$. [Two strongly connected nodes are also weakly connected.]{.aside} \n",
        "\n",
        "The set $\\{j \\in V : i \\text{ is strongly connected to } j\\}$ is called the **strongly connected component** of $i$, and the set $\\{j \\in V : i \\text{ is weakly connected to } j\\}$ is called the **weakly connected component** of $i$. [Intuitively, a weakly connected component is a connected component in the undirected version of the directed graph in which we \"forget\" the directionality of the edges.]{.aside}\n",
        "\n",
        "A directed graph is **strongly connected** if it has only one strongly connected component. A directed graph is **weakly connected** if it is not strongly connected and has only one weakly connected component.\n",
        "\n",
        ":::\n",
        ":::\n",
        "\n",
        "::: {.callout-important}\n",
        "\n",
        "## Exercise\n",
        "\n",
        "Identify the strongly connected components and the weakly connected components in the network below.\n",
        "\n",
        ":::\n"
      ],
      "id": "e952d3aa"
    },
    {
      "cell_type": "code",
      "metadata": {
        "out.width": "80%"
      },
      "source": [
        "#| fig-cap: A directed graph.\n",
        "#| fig-cap-location: margin\n",
        "#| label: fig-strong-component-exercise\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "\n",
        "plot_kwargs = {\"node_size\" : 300, \"edgecolors\" : 'white', \"node_color\" : \"steelblue\", \"width\" : 0.5, \"edge_color\" : \"darkgrey\"}\n",
        "\n",
        "DG = nx.DiGraph()\n",
        "DG.add_edges_from([(1, 2), (2, 3), (2,5), (2,6), (3, 4), (3, 7), (4, 3), (4, 8), (5, 1), (5, 6), (6, 7), (7, 6), (8, 4), (8, 7)])\n",
        "\n",
        "nx.draw(DG, with_labels = True, arrowsize = 20, font_color = 'white', font_weight = 'bold', **plot_kwargs)"
      ],
      "id": "fig-strong-component-exercise",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {.hide .solution}\n",
        "\n",
        "This network has three strongly connected components: $\\{1,2,5\\}, \\ \\{3, 4, 8\\},$ and $\\{6, 7\\}$.\n",
        "\n",
        "The network has only one weakly connected component (this set contains all the nodes). Thus we would say the entire network is weakly connected.\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "In directed networks, we can also define individual node properties that describe all nodes that could reach or be reached by our node of interest.\n",
        "\n",
        "::: {.callout-note icon=false appearance=\"minimal\"}\n",
        "::: {#def-in-out-component}\n",
        "\n",
        "The **in-component** of node $i$ is the set of nodes $\\{j \\in V : \\text{ there is a directed path from } i \\text{ to } j\\}$. \n",
        "\n",
        "\n",
        "\n",
        "The **out-component** of node $i$ is the set of nodes $\\{j \\in V : \\text{ there is a directed path from } j \\text{ to } i\\}$\n",
        "\n",
        "As with connected components, we include the node $i$ itself as a member of its own in- and out-components.\n",
        "\n",
        ":::\n",
        ":::\n",
        "\n",
        "::: {.callout-important}\n",
        "\n",
        "## Exercise\n",
        "\n",
        "Let $C^{\\mathrm{in}}(i)$ and $C^{\\mathrm{out}}(i)$ be the in-component and out-component of node $i$ in a directed network. Describe the sets $C^{\\mathrm{in}}(i) \\cap C^{\\mathrm{out}}(i)$ and $C^{\\mathrm{in}}(i) \\cup C^{\\mathrm{out}}(i)$ in vocabulary we have previously introduced. \n",
        "\n",
        ":::\n",
        "\n",
        "## The Graph Laplacian\n",
        "\n",
        "We now introduce the graph Laplacian. [There are multiple matrices that use this name; the one we introduce here is sometimes called the *combinatorial* graph Laplacian.]{.aside} The Laplacian is a matrix representation of a network that is surprisingly useful in a wide variety of applications. With our focus on components today, we'll find an especially striking property of the Laplacian: the eigenvalues of the Laplacian give us a guide to the connected component structure of a graph. [The Laplacian is also useful in studying random walks and dynamics, for clustering and data analysis, for graph visualization, partitioning, and more! ]{.aside}\n",
        "\n",
        "\n",
        "::: {.callout-note icon=false appearance=\"minimal\"}\n",
        "::: {#def-laplacian}\n",
        "\n",
        "## Laplacian of an Undirected Graph\n",
        "\n",
        "The **(combinatorial) graph Laplacian $L$** of an undirected graph with adjacency matrix $A$ is\n",
        "\n",
        "$$\n",
        "{\\bf L} = {\\bf D} - {\\bf A} \\,\n",
        "$$\n",
        "\n",
        "where ${\\bf D}$ is the diagonal matrix whose diagonal entries $D_{ii} = k_i$ contain the degree of node $i$. An individual entry of the Laplacian can be written \n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "    L_{ij} = \\delta_{ij}k_i - A_{ij} \\,,\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "where $\\delta_{ij}$ is the Kronecker delta function: \n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "    \\delta_{ij} = \\begin{cases} 1 & \\text{if } i = j \\\\ 0 & \\text{otherwise} \\end{cases} \\,.\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        ":::\n",
        ":::\n",
        "\n",
        "Let's construct an undirected graph: \n"
      ],
      "id": "3a0c9b54"
    },
    {
      "cell_type": "code",
      "metadata": {
        "out.width": "80%"
      },
      "source": [
        "#| fig-cap: A undirected graph.\n",
        "#| fig-cap-location: margin\n",
        "#| label: fig-laplacian-example\n",
        "#| column: margin\n",
        "\n",
        "\n",
        "G = nx.Graph()\n",
        "G.add_edges_from([(1, 2), (2, 3), (2,5), (2,6), (3, 4), (3, 7), (4, 3), (4, 8), (5, 1), (5, 6), (6, 7), (7, 6), (8, 4), (8, 7)])\n",
        "\n",
        "fig, ax = plt.subplots(1, 1, figsize = (2, 3))\n",
        "\n",
        "nx.draw(G, with_labels = True, font_color = 'white', font_weight = 'bold', **plot_kwargs)"
      ],
      "id": "fig-laplacian-example",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we'll take a look at the Laplacian matrix. [It is also possible to extract the Laplacian matrix using the NetworkX built-in `nx.laplacian_matrix(G)`.]{.aside}\n"
      ],
      "id": "c0a5ab65"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#---\n",
        "A = nx.to_numpy_array(G)\n",
        "D = np.diag(np.sum(A, axis = 1))\n",
        "L = D - A\n",
        "print(L)\n",
        "#---"
      ],
      "id": "94b76864",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We observe that the diagonal of the Laplacian gives the degrees of each node (from the matrix $\\mathbf{D}$), while the off diagonal entries give the *negatives* of the entries of the adjacency matrix.\n",
        "\n",
        "@def-laplacian  generalizes in a straightforward way for weighted networks with positive weights. There are also variants for directed graphs (including using in-degree or out-degree matrices to build an in-degree Laplacian or an out-degree Laplacian); not all of the properties we describe below hold for these variants.\n",
        "\n",
        "### Properties of the Graph Laplacian\n",
        "\n",
        "We now investigate the mathematical properties of the graph Laplacian. We'll leave proofs of many of these properties as exercises. Throughout, this section, let $\\mathbf{L} \\in \\mathbb{R}^{n\\times n}$ be the combinatorial Laplacian matrix of a graph $G$ on $n$ nodes, and let $\\mathbf{1} \\in \\mathbb{R}^n$ be the vector of ones. \n",
        "\n",
        "::: {.callout-tip icon=false collapse=true}\n",
        "::: {#thm-laplacian}\n",
        "\n",
        "## Elementary Properties of the Graph Laplacian\n",
        "\n",
        "- ${\\bf L}$ is real and symmetric.\n",
        "- ${\\bf L}{\\bf 1} = {\\bf 0}.$ That is, every row sums to 0.\n",
        "- The eigenvalues of $\\mathbf{L}$ are all real. \n",
        "\n",
        ":::\n",
        ":::\n",
        "\n",
        "Another important property of the Laplacian is that it is *positive semi-definite*, which means that all of its eigenvalues are not only real but nonnegative: \n",
        "\n",
        "::: {.callout-tip icon=false collapse=true}\n",
        "::: {#thm-laplacian-psd}\n",
        "\n",
        "## Positive Semi-Definiteness of the Graph Laplacian\n",
        "\n",
        "If $\\lambda$ is an eigenvalue of the Laplacian $\\mathbf{L}$, then $\\lambda \\geq 0$.\n",
        "\n",
        ":::\n",
        ":::\n",
        "\n",
        "\n",
        "In fact, the preceding properties already give us one important piece of information about the spectral structure of the Laplacian: \n",
        "\n",
        "::: {.callout-tip icon=false collapse=true}\n",
        "::: {#thm-laplacian-0-eigenvalue}\n",
        "\n",
        "## 0 is an Eigenvalue of the Graph Laplacian\n",
        "\n",
        "The Laplacian always has at least one zero eigenvalue with corresponding eigenvector ${\\bf 1}.$ [A corollary of this fact is that the Laplacian is not invertible.]{.aside}\n",
        "\n",
        ":::\n",
        ":::\n",
        "\n",
        "Furthermore, the *multiplicity* of the zero eigenvalue gives us information about the number of connected components in the network: \n",
        "\n",
        "\n",
        "::: {.callout-tip icon=false collapse=true}\n",
        "::: {#thm-laplacian-0-multiplicity}\n",
        "\n",
        "## Multiplicity of the 0 Eigenvalue Counts Connected Components\n",
        "\n",
        "- Graph $G$ has $c$ components if and only if its graph Laplacian has exactly $c$ zero eigenvalues (that is, the eigenvalue $\\lambda = 0$ has algebraic multiplicity $c$.)\n",
        "\n",
        ":::\n",
        ":::\n",
        "\n",
        "To prove this statement, we need to show that the algebraic multiplicity of the zero eigenvalue is both a lower and an upper bound on the number of connected components.\n",
        "\n",
        "::: {.callout-important}\n",
        "\n",
        "## Exercise\n",
        "\n",
        "Prove that the algebraic multiplicity is an *upper bound* on the number of connected components. To do so, first argue that you can write the matrix $\\mathbf{L}$ in a block-diagonal form. Then, find an eigenpair with zero eigenvalue for each of the blocks. \n",
        "\n",
        ":::\n",
        "\n",
        "We'll prove that the algebraic multiplicity is also a *lower* bound on the number of connected components as a homework assignment. \n",
        "\n",
        "Here's an example of applying this theorem: we'll construct a graph with 3 connected components and show that the Laplacian has 3 zero eigenvalues.\n"
      ],
      "id": "a61a648b"
    },
    {
      "cell_type": "code",
      "metadata": {
        "out.width": "80%"
      },
      "source": [
        "#| fig-cap: A graph with three connected components.\n",
        "#| fig-cap-location: margin\n",
        "#| label: fig-laplacian-example-3-components\n",
        "#| column: margin\n",
        "\n",
        "fig, ax = plt.subplots(1, 1, figsize = (3, 2))\n",
        "G = nx.Graph()\n",
        "G.add_edges_from([(1, 2), (2, 3), (2,5), (2,6), (3, 4), (3, 7), (4, 3), (4, 8), (5, 1), (5, 6), (6, 7), (7, 6), (8, 4), (8, 7), (9, 10), (10, 11), (11, 9), (12, 13), (13, 14), (14, 12)])\n",
        "\n",
        "pos = nx.planar_layout(G)\n",
        "\n",
        "plot_kwargs.update({\"node_size\" : 100})\n",
        "\n",
        "nx.draw(G,pos, ax = ax, **plot_kwargs)"
      ],
      "id": "fig-laplacian-example-3-components",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can check that there are exactly 3 zero eigenvalues. \n"
      ],
      "id": "3131167b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#---\n",
        "A = nx.to_numpy_array(G)\n",
        "D = np.diag(np.sum(A, axis = 1))\n",
        "L = D - A\n",
        "\n",
        "eigvals, eigvecs = np.linalg.eig(L)\n",
        "num_0_eigs = np.isclose(eigvals, 0, atol = 1e-10).sum() # number of zero eigenvalues\n",
        "#---\n",
        "\n",
        "print(\"Number of zero eigenvalues: \", num_0_eigs)"
      ],
      "id": "63edc8a6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In a graph with just one connected component, @thm-laplacian-0-multiplicity implies that there is exactly one zero eigenvalue of $\\mathbf{L}$. It turns out that if the graph is \"almost disconnected\" into two components, then the second-smallest eigenvalue of the Laplacian will be \"almost 0\". This is part of the motivation behind Laplacian spectral clustering, an algorithm which [we'll see later on](chapters/19-spectral-clustering.qmd). [This kind of structure is often called *community structure* and we will study it much more later in the course.]{.aside} Here's an example of such a graph, which we've plotted alongside the eigenvalues of the Laplacian: \n"
      ],
      "id": "4a94c4d7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| fig-cap: ' (Left) A graph which is almost disconnected into two components; deleting two edges would separate the network. (Right): the eigenvalues of the Laplacian of the graph in ascending order. The second-smallest eigenvalue is very close to 0, which reflects the near-disconnectedness of the graph.'\n",
        "#| label: fig-laplacian-almost-disconnected\n",
        "fig, ax = plt.subplots(1, 2, figsize = (6, 3))\n",
        "\n",
        "G = nx.stochastic_block_model([10, 10], [[0.5, 0.02], [0.02, 0.5]], seed = 1234)\n",
        "\n",
        "pos = nx.spring_layout(G, seed = 1234)\n",
        "\n",
        "nx.draw(G, pos, ax = ax[0], **plot_kwargs)\n",
        "\n",
        "A = nx.to_numpy_array(G)\n",
        "D = np.diag(np.sum(A, axis = 1))\n",
        "L = D - A\n",
        "\n",
        "eigvals, eigvecs = np.linalg.eig(L)\n",
        "\n",
        "ax[1].scatter(np.arange(len(eigvals)), np.sort(eigvals), facecolor = 'white', edgecolor = 'black')\n",
        "\n",
        "ax[1].set(xlabel = \"Eigenvalue index\", ylabel = \"Eigenvalue of Laplacian\")"
      ],
      "id": "fig-laplacian-almost-disconnected",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The eigenvalue on the very far left is the zero eigenvalue guaranteed for any graph, while the very small eigenvalue right next to it reflects the structure of the graph as \"almost disconnected\" into two components. \n",
        "\n",
        "\n",
        "### The Graph Laplacian as a Smoothness Measure\n",
        "\n",
        "Suppose that we have a vector $\\mathbf{x} \\in \\mathbb{R}^n$, where we interpret entry $x_i$ as describing some quantity at node $i$. The Laplacian matrix can be used to measure the \"smoothness\" of this vector on the graph, by which we mean the extent to which neighboring nodes have similar values of $x$. One way to quantify this is using the measure\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "    S(\\mathbf{x}) = \\frac{1}{2}\\sum_{i = 1}^n \\sum_{j = 1}^n A_{ij}(x_i - x_j)^2 \\,.\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "The term corresponding to $i$ and $j$ in $S(\\mathbf{x})$ is zero if either $A_{ij} = 0$ (i.e. node $i$ is not connected to node $j$) or if $x_i = x_j$ (i.e. nodes $i$ and $j$ have the same values in their corresponding entries of $\\mathbf{x}$). So, intuitively, $S(\\mathbf{x})$ is small when connected nodes have similar entries in $\\mathbf{x}$ and large when connected nodes have very different entries in $\\mathbf{x}$. The Laplacian can be used to concisely represent the smoothness measure $S(\\mathbf{x})$: \n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "    S(\\mathbf{x}) &= \\frac{1}{2}\\sum_{i = 1}^n \\sum_{j = 1}^n A_{ij}(x_i - x_j)^2 \\\\ \n",
        "    &= \\frac{1}{2} \\sum_{i = 1}^n \\sum_{j = 1}^n A_{ij}(x_i^2 - 2x_ix_j + x_j^2) \\\\\n",
        "    &= \\frac{1}{2} \\sum_{i = 1}^n \\sum_{j = 1}^n A_{ij}x_i^2 - \\sum_{i = 1}^n \\sum_{j = 1}^n A_{ij}x_ix_j + \\frac{1}{2}\\sum_{i = 1}^n \\sum_{j = 1}^n A_{ij}x_j^2 \\\\\n",
        "    &= \\frac{1}{2} \\sum_{i = 1}^n k_i x_i^2 - \\sum_{i = 1}^n \\sum_{j = 1}^n A_{ij}x_ix_j + \\frac{1}{2} \\sum_{j = 1}^n k_j x_j^2 \n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "In the last line, we've used the definition of the degree: $k_i = \\sum_{j = 1}^n A_{ij}$. Now we need to use an indexing trick. Let $\\delta_{ij}$ be the Kronecker delta, which is 1 if $i = j$ and 0 otherwise. Then, we can write \n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "    \\frac{1}{2} \\sum_{i = 1}^n k_i x_i^2 + \\frac{1}{2} \\sum_{j = 1}^n k_j x_j^2 = \\sum_{i = 1}^n\\sum_{j = 1}^n \\delta_{ij} k_i  x_i x_j\\;,\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "which allows us to write our entire smoothness measure as \n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "    S(\\mathbf{x}) &= \\sum_{i = 1}^n\\sum_{j = 1}^n \\left(\\delta_{ij} k_i   - A_{ij}\\right)x_ix_j \\\\ \n",
        "    &= \\sum_{i = 1}^n\\sum_{j = 1}^n L_{ij}x_ix_j \\\\ \n",
        "    &= \\mathbf{x}^T\\mathbf{Lx} \\,.\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "\n",
        "So, our smoothness measure is the quadratic form $\\mathbf{x}^T\\mathbf{Lx}$. The role of the Laplacian in measuring the smoothness of functions defined on graphs is another perspective on its use in both algorithms and modeling of dynamical systems. \n",
        "\n",
        "\n",
        "### The Graph Laplacian as a Diffusion Operator\n",
        "\n",
        "One of the many important properties of the graph Laplacian is that it describes many *spreading* or *diffusion* processes that take place on networks. Here's an example: suppose that we \"heat up\" a single node on the network, and then allow heat to flow along the network edges. The Laplacian matrix gives a concise description of how this heat spreads over the network. Let $\\mathbf{x} \\in \\mathbb{R}^n$ be the vector whose $i$th entry gives the amount of heat currently on node $i$. Then, the vector $\\delta \\mathbf{x} = -\\mathbf{Lx}$ is proportional to rate of change of heat at each node. If we imagine that heat moves in discrete time, our update would be [One perspective on this update is that it is the gradient flow associated with minimization of the smoothness measure $S(\\mathbf{x})$ from the previous section.]{.aside}\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\mathbf{x} \\gets \\mathbf{x} -\\alpha\\mathbf{Lx} \\,,\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "where $\\alpha$ is some constant that describes the rate of heat transfer. Let's see how this looks: \n"
      ],
      "id": "2218de8e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| fig-cap : \"Snapshots of heat diffusion on a network. Colors are shown on a logarithmic scale for visualization purposes.\"\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "\n",
        "fig, axarr = plt.subplots(2, 3, figsize = (7, 3.7))\n",
        "\n",
        "# create a network for visualization and set up a layout\n",
        "n = 50\n",
        "rad = 0.25\n",
        "G = nx.random_geometric_graph(n, rad, seed = 1234)\n",
        "\n",
        "layout = nx.kamada_kawai_layout(G)\n",
        "\n",
        "# construct the Laplacian matrix\n",
        "A = nx.to_numpy_array(G)\n",
        "D = np.diag(np.sum(A, axis = 1))\n",
        "L = D - A\n",
        "\n",
        "# rate of heat transfer\n",
        "rate = 0.12\n",
        "\n",
        "# initial condition: all heat on a single node\n",
        "x = np.zeros(n)\n",
        "x[20] = 10\n",
        "\n",
        "# main loop\n",
        "for i, ax in enumerate(axarr.flatten()):\n",
        "    nx.draw(G, ax = ax, node_size = 20, edge_color = 'gray', node_color = x, width = 0.5, pos = layout, cmap = \"coolwarm\", vmin = 0, vmax = 1)\n",
        "    ax.set_title(\"$t = \" + str(i) + \"$\")\n",
        "\n",
        "    # Laplacian dynamical update\n",
        "    x -= rate*L@x"
      ],
      "id": "993f6fc2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The Laplacian operator also has many other applications in network science, many of which we will study later in these notes. \n"
      ],
      "id": "3ad23ba6"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python2",
      "language": "python",
      "display_name": "Python 2",
      "path": "/Users/philchodrow/Library/Jupyter/kernels/python2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}