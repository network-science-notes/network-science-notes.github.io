<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.10">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>15&nbsp; Random Walks – Network Science: Models, Mathematics, and Computation</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../chapters/51-agent-based-modeling.html" rel="next">
<link href="../chapters/41-link-prediction.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-2d9718c933debafcce942f9b212640bc.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-c1bdd270c1c0708cd2ff05417efafcc5.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-sidebar floating slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../chapters/50-random-walks.html">Applications and Extensions</a></li><li class="breadcrumb-item"><a href="../chapters/50-random-walks.html"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Random Walks</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Network Science: Models, Mathematics, and Computation</a> 
    </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Welcome</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Network Fundamentals</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/01-networkrepresentations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Networks and Their Representations</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/02-degree-walks-paths.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Degree, Walks, and Paths</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/03-components-laplacian.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Components and the Graph Laplacian</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Measuring Networks</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/04-centrality.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Centrality and Importance</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/05-viz.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Visualizing Networks and Why You Shouldn’t</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/06-modularity.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Homophily, assortativity, and modularity</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Real-World Networks</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/07-real-world.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Structure of Empirical Networks</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/08-power-laws.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Power Law Degree Distributions</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Models of Networks</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/09-random-graphs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Random Graphs: Erdős–Rényi</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/10-configuration-model.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Configuration models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/11-generating-functions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Probability Generating Functions</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text">Network Algorithms</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/13-modularity-maximization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Community Detection and Modularity Maximization</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/19-spectral-clustering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Spectral Clustering</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/41-link-prediction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Link Prediction and Feedback Loops</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true">
 <span class="menu-text">Applications and Extensions</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/50-random-walks.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Random Walks</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/51-agent-based-modeling.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Agent-Based Modeling on Networks</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/52-epidemiology.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Epidemic Models on Networks</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">
 <span class="menu-text">Appendices</span></span>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Contents</h2>
   
  <ul>
  <li><a href="#sec-srw" id="toc-sec-srw" class="nav-link active" data-scroll-target="#sec-srw">The Simple Random Walk</a>
  <ul class="collapse">
  <li><a href="#stationary-distribution-existence-and-uniqueness" id="toc-stationary-distribution-existence-and-uniqueness" class="nav-link" data-scroll-target="#stationary-distribution-existence-and-uniqueness">Stationary Distribution: Existence and Uniqueness</a></li>
  <li><a href="#stationary-distribution-structure" id="toc-stationary-distribution-structure" class="nav-link" data-scroll-target="#stationary-distribution-structure">Stationary Distribution: Structure</a></li>
  </ul></li>
  <li><a href="#exploration-and-ranking-pagerank" id="toc-exploration-and-ranking-pagerank" class="nav-link" data-scroll-target="#exploration-and-ranking-pagerank">Exploration and Ranking: PageRank</a>
  <ul class="collapse">
  <li><a href="#implementation" id="toc-implementation" class="nav-link" data-scroll-target="#implementation">Implementation</a></li>
  </ul></li>
  <li><a href="#seeded-pagerank" id="toc-seeded-pagerank" class="nav-link" data-scroll-target="#seeded-pagerank">Seeded PageRank</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../chapters/50-random-walks.html">Applications and Extensions</a></li><li class="breadcrumb-item"><a href="../chapters/50-random-walks.html"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Random Walks</span></a></li></ol></nav>
<div class="quarto-title">
</div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p><em>Open the live notebook in Google Colab <a href="https://colab.research.google.com/github/network-science-notes/network-science-notes.github.io/blob/main/docs/live-notebooks/50-random-walks.ipynb">here</a>.</em></p>
<p>Suppose that we have a very large network, and we’d like to explore it. Perhaps we don’t even have access to all the edges. This is a common situation in data collection. A webscraper for gathering data, for example, doesn’t have access to the entire network of webpages to be scraped; usually it has access to <em>one page at a time</em> and the links it contains. At each stage, the webscraper needs to follow a link in order to get the next piece of information.</p>
<p>There are many ways to explore a network, but the most fundamental one is the <em>simple random walk</em>. We’ll discuss the simple random walk, highlight some of its core properties, and connect it to some ideas that we’ve already seen. Then, we’ll introduce the <em>teleporting random walk</em>, which is the foundation of the internet-changing PageRank algorithm originally used by Google. Finally, we’ll take another look network navigation and the small-world phenomenon.</p>
<section id="sec-srw" class="level2">
<h2 class="anchored" data-anchor-id="sec-srw">The Simple Random Walk</h2>
<p>The simple random walk is easier to describe in English than it is to formulate mathematically. In intuitive terms, we imagine a walker who starts at some node <span class="math inline">\(i\)</span> in the graph. The walker then picks one of the neighbors <span class="math inline">\(j\)</span> of <span class="math inline">\(i\)</span> uniformly at random, and moves to <span class="math inline">\(j\)</span>. Then, the walker picks one of the neighbors <span class="math inline">\(k\)</span> of <span class="math inline">\(j\)</span> uniformly at random, and moves to <span class="math inline">\(k\)</span>, and so on.</p>
<div class="callout callout-style-simple callout-note no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="def-simple-random-walk" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 15.1 (Simple Random Walk (SRW))</strong></span> A <strong>simple random walk</strong> on a graph <span class="math inline">\(G\)</span> with adjacency matrix <span class="math inline">\(\mathbf{A}\in \mathbb{R}^{n\times n}\)</span> is a countable sequence of random variables <span class="math inline">\(X_1,\ldots,X_t,\ldots\)</span> which take values in the node set <span class="math inline">\(N\)</span> of <span class="math inline">\(G\)</span>. We have <span class="math display">\[
\begin{aligned}
\mathbb{P}(X_{t+1} = i | X_t = j_t, X_{t-1} = j_{t-1},\ldots,X_{1} = j_1) &amp;=  \mathbb{P}(X_{t+1} = i | X_t = j_t) \\
&amp;= \begin{cases}
        \frac{1}{k_j} &amp;\quad j \text{ is connected to } i \\
        0 &amp;\quad \text{otherwise.}
    \end{cases} \\
    &amp;= \frac{a_{ij}}{k_j}\;.
\end{aligned}
\]</span></p>
</div>
</div>
</div>
</div>
<p>In <a href="#def-simple-random-walk" class="quarto-xref">Definition&nbsp;<span>15.1</span></a>, the first equality is the <em><a href="https://en.wikipedia.org/wiki/Markov_property">Markov property</a></em>: the future state of the random walk depends only on where it is right now (i.e.&nbsp;the value of <span class="math inline">\(X_t\)</span>), not where it’s been previously. The second and third equalities give mathematical structure to the idea of “picking a node connected to <span class="math inline">\(j\)</span> uniformly at random.”</p>
<div class="callout callout-style-simple callout-note no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="def-transition-matrix" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 15.2 (Transition Matrix of a SRW)</strong></span> The <strong>transition matrix</strong> of a simple random walk on a connected graph <span class="math inline">\(G\)</span> with adjacency matrix <span class="math inline">\(\mathbf{A}\)</span> is <span class="math inline">\(\mathbf{P} = \mathbf{A}\mathbf{D}^{-1}\)</span>. Its entries are <span class="math inline">\(p_{ij} = a_{ij}/k_j\)</span>, where <span class="math inline">\(k_j\)</span> is the degree of node <span class="math inline">\(j\)</span> and <span class="math inline">\(\mathbf{D}\)</span> is the diagonal matrix whose <span class="math inline">\(jj\)</span>th entry is <span class="math inline">\(k_j\)</span>.</p>
</div>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-caution no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong><em>Exercise</em></strong>: Let <span class="math inline">\(p_{ij}\)</span> denote the entries of <span class="math inline">\(\mathbf{P}\)</span>. Check that <span class="math inline">\(\sum_{i \in N} p_{ij} = 1\)</span>, and interpret this fact. We say a matrix with this property is <strong>(column) stochastic</strong>.</p>
</div>
</div>
</div>

<p>What does the transition matrix do? Well, we can use the law of total probability to write: <span class="math display">\[
\begin{aligned}
\mathbb{P}(X_{t+1} = i) &amp;= \sum_{j \in N}\mathbb{P}(X_{t+1} = i|X_{t} = j)\mathbb{P}(X_t = j) \\
&amp;= \sum_{j \in N}p_{ij}\mathbb{P}(X_t = j)\;.
\end{aligned}
\]</span></p>
<p>Let <span class="math inline">\(\mathbf{q}(t)\)</span> be the vector with entries <span class="math inline">\(q_i(t) = \mathbb{P}(X_{t} = i)\)</span>. We have just shown the most important relation in the study of random walks and their generalizations, Markov chains:</p>
<div class="callout callout-style-simple callout-tip no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><span id="eq-transition"><span class="math display">\[
\mathbf{q}(t+1) = \mathbf{P}\mathbf{q}(t)
\tag{15.1}\]</span></span></p>
</div>
</div>
</div>
<p><a href="#eq-transition" class="quarto-xref">Equation&nbsp;<span>15.1</span></a> has an immediate consequence: <span class="math inline">\(\mathbf{q}(t) = \mathbf{P}^{t}\mathbf{q}(0)\)</span>. So, if we know the <em>initial distribution</em> <span class="math inline">\(\mathbf{q}(0)\)</span> describing the location at which the walker begins, we can get all other information we need from the matrix <span class="math inline">\(\mathbf{P}\)</span> and its powers.</p>
<section id="stationary-distribution-existence-and-uniqueness" class="level3">
<h3 class="anchored" data-anchor-id="stationary-distribution-existence-and-uniqueness">Stationary Distribution: Existence and Uniqueness</h3>
<p>Throughout this section, we assume that the graph <span class="math inline">\(G\)</span> is connected.</p>
<div class="callout callout-style-simple callout-note no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p>We say that an SRW has a <em>stationary distribution</em> <span class="math inline">\(\pi \in \mathbb{R}^n\)</span> if <span class="math inline">\(\lim_{t\rightarrow \infty} \mathbf{q}(t) = \mathbf{\pi}\)</span>, <em>regardless of the initial distribution</em> <span class="math inline">\(\mathbf{q}(0)\)</span>.</p>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-note no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="def-periodic" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 15.3</strong></span> A graph is <em>aperiodic</em> if the greatest common divisor of lengths of its cycles is 1. A graph is <em>periodic</em> if it is not aperiodic.</p>
</div>
</div>
</div>
</div>
<p>A simple example of a periodic graph is a <span class="math inline">\(k\)</span>-cycle. A less simple example is a <em>bipartite graph</em>, in which each node can be separated into one of two classes <span class="math inline">\(S_1\)</span> and <span class="math inline">\(S_2\)</span> such that nodes in <span class="math inline">\(S_1\)</span> only connect to nodes in <span class="math inline">\(S_2\)</span> (and not to any other nodes in <span class="math inline">\(S_1\)</span>). You can check that bipartiteness implies that every cycle has length divisible by 2, so the graph is periodic.</p>
<div class="callout callout-style-simple callout-tip no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="thm-stationary" class="theorem">
<p><span class="theorem-title"><strong>Theorem 15.1</strong></span> Suppose that <span class="math inline">\(G\)</span> is connected and aperiodic. Then,</p>
<ul>
<li><span class="math inline">\(G\)</span> has a stationary distribution <span class="math inline">\(\pi\)</span>.</li>
<li>This stationary distribution is unique.</li>
<li>The stationary distribution is the unique eigenvector of the transition matrix <span class="math inline">\(\mathbf{P}\)</span> with eigenvalue <span class="math inline">\(1\)</span>.</li>
</ul>
</div>
</div>
</div>
</div>
<p><a href="#thm-stationary" class="quarto-xref">Theorem&nbsp;<span>15.1</span></a> is actually a theorem about discrete-time finite-state Markov chains in general, and its full proof is beyond the scope of this course. Here’s a sketch:</p>
<ol type="1">
<li>The condition that <span class="math inline">\(G\)</span> is connected implies that the matrix <span class="math inline">\(\mathbf{P}\)</span> is <a href="https://en.wikipedia.org/wiki/Perron%E2%80%93Frobenius_theorem#Classification_of_matrices">irreducible</a>.</li>
<li>This allows us to apply the <a href="https://en.wikipedia.org/wiki/Perron–Frobenius_theorem">Perron-Frobenius theorem</a> to conclude that <span class="math inline">\(\mathbf{P}\)</span> has a unique eigenvector with strictly positive entries, which we’ll call <span class="math inline">\({\bf \pi}\)</span>. Since <span class="math inline">\(\mathbf{P}\)</span> is column stochastic, a direct calculation shows that the corresponding eigenvalue of <span class="math inline">\({\bf \pi}\)</span> is 1, and we have <span class="math inline">\(\pi = \mathbf{P}\pi\)</span>.</li>
<li>One further shows that <span class="math inline">\(\lim_{t \rightarrow \infty}\mathbf{P}^t\)</span> exists and that its rows become equal to the eigenvector <span class="math inline">\(\pi\)</span> (this is related to power iteration).</li>
<li>Because each row of limiting matrix describe the long-run behavior of the random walk from a given starting node, one infers that <span class="math inline">\(\pi\)</span> is indeed a stationary state. Because all the rows agree in the limit, one infers that <span class="math inline">\(\pi\)</span> is the only such stationary state.</li>
</ol>
</section>
<section id="stationary-distribution-structure" class="level3">
<h3 class="anchored" data-anchor-id="stationary-distribution-structure">Stationary Distribution: Structure</h3>
<p>We know from <a href="#thm-stationary" class="quarto-xref">Theorem&nbsp;<span>15.1</span></a> that there is a unique stationary distribution for the simple random walk, and that this distribution describes, in the long-term, the amount of time that the walker spends on a node. What actually <em>is</em> the stationary distribution? For many Markov chains, including more complicated random walks, it can be difficult to describe the stationary distribution exactly. In this case the answer is surprisingly simple, although it’s one of those things that’s much easier to check than it is to find in the first place.</p>
<div class="callout callout-style-simple callout-note no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="thm-degree" class="theorem">
<p><span class="theorem-title"><strong>Theorem 15.2 (Stationary Distribution of an SRW)</strong></span> The stationary distribution of an SRW is <span class="math inline">\(\pi = \frac{1}{2m}\mathbf{k}\)</span>, where <span class="math inline">\(\mathbf{k}\)</span> is the vector of node degrees.</p>
</div>
</div>
</div>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>We can do a direct calculation:</p>
<p><span class="math display">\[
\begin{aligned}
\mathbf{P}\pi = \mathbf{A}\mathbf{D}^{-1}\left(\frac{1}{2m}\mathbf{k}\right) = \frac{1}{2m}\mathbf{A}\mathbf{1}
= \frac{1}{2m}\mathbf{k}
= \pi\;.
\end{aligned}
\]</span></p>
<p>For the second equality we have used the quickly-checked identity <span class="math inline">\(\mathbf{D}^{-1}\mathbf{k} = \mathbf{1}\)</span>, while for the third we have used the formula <span class="math inline">\(\mathbf{k} = \mathbf{A}\mathbf{1}\)</span>.</p>
</div>
<p>So, for simple random walks, <span class="math inline">\(\mathbb{P}(X_t = i)\)</span> when <span class="math inline">\(t\)</span> is large is approximately <span class="math inline">\(k_i/2m\)</span>, proportional to the degree of node <span class="math inline">\(i\)</span>. The intuition here is that the amount of time I spend in state is directly proportional to the number of ways that I can enter that state.</p>
</section>
</section>
<section id="exploration-and-ranking-pagerank" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="exploration-and-ranking-pagerank">Exploration and Ranking: PageRank</h2>
<div class="page-columns page-full"><p>PageRank is the algorithm that originally made Google a dominant player in the domain of web search. The idea of PageRank is again to explore the graph using a random exploration process. The underlying process is closely related to the simple random walk that we described earlier. However, there are two important differences.</p><div class="no-row-height column-margin column-container"><span class="margin-aside"><span class="citation" data-cites="brin1998anatomy">Brin and Page (<a href="#ref-brin1998anatomy" role="doc-biblioref">1998</a>)</span></span></div></div>
<ol type="1">
<li>First, PageRank works on <em>directed</em> graphs. This matches the original application area; the web can be viewed as a <em>directed</em> network of links between pages. The reason directedness is so important is that, if <span class="math inline">\(i \rightarrow j\)</span> (<span class="math inline">\(i\)</span> links to <span class="math inline">\(j\)</span>), it doesn’t follow that <span class="math inline">\(j\rightarrow i\)</span>. Capturing these kinds of asymmetric relationships is very important for reasonable ranking procedures.</li>
<li>Unlike the SRW, PageRank is able to explore graphs that are non-ergodic.</li>
</ol>
<p>So, suppose we have a <em>directed</em> graph with adjacency matrix <span class="math inline">\(\mathbf{A}\)</span>. The important thing to remember is that now <span class="math inline">\(\mathbf{A}\)</span> is not required to be symmetric. We interpret the entries of the adjacency matrix so that <span class="math inline">\(a_{ij} = 1\)</span> if <span class="math inline">\(j \rightarrow i\)</span>. Since <span class="math inline">\(\mathbf{A}\)</span> need not be symmetric, <span class="math inline">\(a_{ij} \neq a_{ji}\)</span> in general.</p>
<p>The definition of a random walk on a directed graph is very similar to the definition on an undirected graph. It is again a sequence of random variables with the Markov property; only the transition probabilities differ.</p>
<div class="callout callout-style-simple callout-note no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="def-directed-SRW" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 15.4 (Simple Random Walk on a Directed Graph)</strong></span> The SRW on a directed graph has transition probabilities <span class="math display">\[
\mathbb{P}(X_{t+1} = i | X_t = j) = \frac{a_{ij}}{k_j^{\mathrm{out}}}\;,
\]</span> where <span class="math inline">\(k_j^{\mathrm{out}} = \sum_{i \in N}a_{ij}\)</span> is the number of outgoing links from node <span class="math inline">\(j\)</span>. The transition matrix of this walk is <span class="math display">\[
\mathbf{P} = \mathbf{A}(\mathbf{D}^{\mathrm{out}})^{-1}\;.
\]</span></p>
</div>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-caution no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p>Because <span class="math inline">\(\mathbf{A}\)</span> is not symmetric, we can also define <span class="math inline">\(k_i^{\mathrm{in}} = \sum_{j \in N}a_{ij}\)</span>, the number of incoming links to node <span class="math inline">\(j\)</span>. Importantly, <span class="math inline">\(k_i^{\mathrm{in}} \neq k_i^{\mathrm{out}}\)</span> in general.</p>
</div>
</div>
</div>
<p>Many of the same considerations from the undirected setting carry over to the directed setting.</p>
<div class="callout callout-style-simple callout-tip no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="thm-stationary-directed" class="theorem">
<p><span class="theorem-title"><strong>Theorem 15.3 (Stationary Distributions of Directed Random Walks)</strong></span> Suppose that:</p>
<ol type="1">
<li>There exists some integer power <span class="math inline">\(t &gt; 0\)</span> such that every entry of <span class="math inline">\(\mathbf{A}^t\)</span> is positive.</li>
<li>The greatest common divisor of the <em>directed</em> cycles in <span class="math inline">\(G\)</span> is 1.</li>
</ol>
<p>Then, the SRW on <span class="math inline">\(G\)</span> has a stationary distribution <span class="math inline">\(\pi\)</span>, which is a solution of the eigenproblem <span class="math display">\[
\pi = \mathbf{P}\pi\;.
\]</span></p>
</div>
</div>
</div>
</div>
<p>Condition (1) in <a href="#thm-stationary-directed" class="quarto-xref">Theorem&nbsp;<span>15.3</span></a> is essentially a connectedness condition: it says that there has to be a directed path from every node to every other node in the network. So, as you might reasonably expect, the directed random walk doesn’t really overcome the need for the graph to be connected. This can be a problem for network exploration, as it’s more common for directed networks to not be connected in this way.[A bit more subtly, directed graphs that are <em>almost</em> disconnected are subject to <em>slow mixing</em> of the random walk, which implies very inefficient exploration of the network.] PageRank overcomes this limitation by allowing the walker to randomly hop to new nodes, independent of the network structure.</p>
<div class="callout callout-style-simple callout-note no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="def-pagerank-walk" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 15.5 (PageRank Random Walk)</strong></span> The <strong>PageRank random walk</strong> has two parameters:</p>
<ul>
<li>The <em>teleportation vector</em> <span class="math inline">\(\mathbf{v} \in \mathbb{R}^n_+\)</span>, which we assume to satisfy <span class="math inline">\(\sum_{i\in N}v_i = 1\)</span>.</li>
<li>The <em>teleportation rate</em> <span class="math inline">\(\alpha\in [0,1]\)</span>.</li>
</ul>
<p>This walk has transition probabilities <span id="eq-pagerank-transition"><span class="math display">\[
\mathbb{P}(X_{t+1} = i|X_{t}=j) = (1-\alpha)\frac{a_{ij}}{k_j^{\mathrm{out}}} + \alpha v_i\;.
\tag{15.2}\]</span></span></p>
<p>Its transition matrix is</p>
<p><span class="math display">\[
\mathbf{P} = (1-\alpha) \mathbf{A}(\mathbf{D}^{\mathrm{out}})^{-1} + \alpha \mathbf{V}\;,
\]</span></p>
<p><span class="math display">\[
\mathbf{V} = \left[\begin{matrix}
    | &amp; | &amp; \cdots &amp; | \\
    \mathbf{v} &amp; \mathbf{v} &amp; \cdots &amp; \mathbf{v} \\
    | &amp; | &amp; \cdots &amp; |
\end{matrix}\right]\;.
\]</span></p>
</div>
</div>
</div>
</div>
<p>Here’s the intuitive way to think about this walk. At each time step, the walker flips a weighted coin with probability of heads equal to <span class="math inline">\(\alpha\)</span>.</p>
<ul>
<li>If heads, the walker chooses to sample from the probability distribution encoded by <span class="math inline">\(\mathbf{v}\)</span>. That is, the walker chooses from among all the nodes in <span class="math inline">\(N\)</span>, and picks node <span class="math inline">\(i\)</span> with probability <span class="math inline">\(v_i\)</span>.</li>
<li>If tails, the walker instead follows a link, just like in the directed random walk.</li>
</ul>
<p>This is why there are two terms in the transition probability in <a href="#eq-pagerank-transition" class="quarto-xref">Equation&nbsp;<span>15.2</span></a>. The first term corresponds to the “tails” scenario in which the walker does a step corresponding to the directed random walk, while the second term corresponds to teleportation.</p>
<p>The standard choice of the teleportation vector is <span class="math inline">\(\mathbf{v} = \frac{1}{n}\mathbf{1}\)</span>, so each node has an equal probability of being chosen for teleportation. However, it’s also possible to take other approaches, as we’ll see in a moment.</p>
<div class="callout callout-style-simple callout-note no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="thm-pagerank" class="theorem">
<p><span class="theorem-title"><strong>Theorem 15.4 (Stationary Distribution of PageRank)</strong></span> Suppose that there exists an integer power <span class="math inline">\(t\)</span> such that <span class="math inline">\(\mathbf{P}^t\)</span> has all entries strictly positive. Then, the PageRank random walk has a unique stationary distribution, and this distribution may again be found by solving <span class="math inline">\(\pi = \mathbf{P}\pi\)</span>.</p>
</div>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-caution no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong>Exercise</strong>: Show that, when <span class="math inline">\(\mathbf{v} = \frac{1}{n}\mathbf{1}\)</span>, <a href="#thm-pagerank" class="quarto-xref">Theorem&nbsp;<span>15.4</span></a> implies that the PageRank walk always has a stationary distribution, regardless of the graph.</p>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-caution no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong>Challenge</strong>: Give a necessary and sufficient condition in terms of <span class="math inline">\(\mathbf{A}\)</span> and <span class="math inline">\(\mathbf{v}\)</span> for PageRank to have a stationary distribution.</p>
</div>
</div>
</div>
<section id="implementation" class="level3">
<h3 class="anchored" data-anchor-id="implementation">Implementation</h3>
<p>Let’s code up a quick example to visualize PageRank. We’ll use the Hamilton Mentions graph:</p>
<div id="41a0949a" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Show code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> networkx <span class="im">as</span> nx</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">"https://philchodrow.github.io/PIC16A/homework/HW3-hamilton-data.csv"</span>, </span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>names <span class="op">=</span> [<span class="st">"mentioner"</span>, <span class="st">"mentioned"</span>])</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df[df[<span class="st">"mentioner"</span>] <span class="op">!=</span> df[<span class="st">"mentioned"</span>]]</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>G <span class="op">=</span> nx.from_pandas_edgelist(df, </span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>                            source <span class="op">=</span> <span class="st">"mentioner"</span>, </span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>                            target <span class="op">=</span> <span class="st">"mentioned"</span>, </span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>                            edge_attr<span class="op">=</span><span class="va">None</span>, </span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>                            create_using<span class="op">=</span>nx.DiGraph())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>There are a few nodes in this network with no outgoing edges. while there are modifications we can make to handle this kind of case, we can also just remove them from the graph.</p>
<div id="742ed97a" class="cell" data-execution_count="2">
<details class="code-fold">
<summary>Show code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">2</span>):</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>    G <span class="op">=</span> G.subgraph([name <span class="cf">for</span> name, val <span class="kw">in</span> G.out_degree() <span class="cf">if</span> val <span class="op">&gt;</span> <span class="dv">0</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Now we can write our PageRank function. We’ll compute the transition matrix <span class="math inline">\(\mathbf{P}\)</span> and find its leading eigenvector.</p>
<div id="45d2451f" class="cell" data-execution_count="3">
<details class="code-fold">
<summary>Show code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> pagerank(G, v, alpha <span class="op">=</span> <span class="fl">0.15</span>):</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span> np.isclose(v.<span class="bu">sum</span>(), <span class="fl">1.0</span>)</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># construct the PR transition matrix</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>    A  <span class="op">=</span> nx.to_numpy_array(G).T</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>    K  <span class="op">=</span> np.diag(A.<span class="bu">sum</span>(axis <span class="op">=</span> <span class="dv">0</span>))     <span class="co"># K^out</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>    P_ <span class="op">=</span> A<span class="op">@</span>np.linalg.inv(K)           <span class="co"># random walk matrix</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>    V  <span class="op">=</span> np.outer(v, np.ones(<span class="bu">len</span>(v))) <span class="co"># teleportation matrix</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>    P <span class="op">=</span> (<span class="dv">1</span><span class="op">-</span>alpha)<span class="op">*</span>P_ <span class="op">+</span> alpha<span class="op">*</span>V        <span class="co"># overall transition matrix</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># grab the eigenvector with eigenvalue 1, normalize it and return. </span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>    eigs <span class="op">=</span> np.linalg.eig(P)        </span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>    pi <span class="op">=</span> eigs[<span class="dv">1</span>][:,np.isclose(eigs[<span class="dv">0</span>], <span class="fl">1.0</span>)]</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>    pi <span class="op">=</span> np.<span class="bu">abs</span>(pi) <span class="op">/</span> np.<span class="bu">abs</span>(pi).<span class="bu">sum</span>()</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> pi</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="19add1f6" class="cell" data-execution_count="4">
<details class="code-fold">
<summary>Show code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> draw_pagerank(G, v,  layout, alpha <span class="op">=</span> <span class="fl">0.15</span>):</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>    pi <span class="op">=</span> pagerank(G, v, alpha <span class="op">=</span> alpha)</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>    nx.draw(G, layout, </span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>            node_size <span class="op">=</span> <span class="dv">5000</span><span class="op">*</span>pi, </span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>            with_labels <span class="op">=</span> <span class="va">True</span>,</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>            edge_color <span class="op">=</span> <span class="st">"lightgray"</span>, </span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>            node_color <span class="op">=</span> <span class="st">"lavender"</span>,</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>            edgecolors  <span class="op">=</span> <span class="st">"darkgray"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Now we can visualize the PageRank stationary distribution for different choices of the teleportation vector <span class="math inline">\(\mathbf{v}\)</span> and the teleportation rate <span class="math inline">\(\alpha\)</span>:</p>
<div id="e57a851d" class="cell" data-execution_count="5">
<details class="code-fold">
<summary>Show code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>layout <span class="op">=</span> nx.fruchterman_reingold_layout(G)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="bu">len</span>(G.nodes())</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>v <span class="op">=</span> <span class="dv">1</span><span class="op">/</span>n<span class="op">*</span>np.ones(n)</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>draw_pagerank(G, v, layout, alpha <span class="op">=</span> <span class="fl">0.1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="50-random-walks_files/figure-html/cell-6-output-1.png" class="figure-img" width="691" height="499"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="seeded-pagerank" class="level2">
<h2 class="anchored" data-anchor-id="seeded-pagerank">Seeded PageRank</h2>
<p>A useful feature of the way we’ve defined PageRank is that we can choose different teleportation vectors <span class="math inline">\(\mathbf{v}\)</span> in order to explore different parts of the graph. For example, suppose that we are especially interested in the part of the network surrouding certain characters. We can just change the teleportation vector <span class="math inline">\(\mathbf{v}\)</span> to highlight those specific characters. This approach is often called “personalized” or “seeded” PageRank.</p>
<div id="491e8001" class="cell" data-execution_count="6">
<details class="code-fold">
<summary>Show code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>v <span class="op">=</span> np.array([<span class="dv">1</span> <span class="cf">if</span> i <span class="op">==</span> <span class="st">"kingGeorge"</span> <span class="cf">else</span> <span class="dv">0</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">list</span>(G.nodes())])</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>draw_pagerank(G, v, layout, alpha <span class="op">=</span> <span class="fl">0.1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="50-random-walks_files/figure-html/cell-7-output-1.png" class="figure-img" width="691" height="499"></p>
</figure>
</div>
</div>
</div>
<p>This time, we’ve highlighted the node corresponding to the character King George. Whereas when using the “basic” version of PageRank Hamilton, Burr, Washington, and Jefferson are all very important characters, in the personalized versio, Washington emerges as clearly the most important.</p>
<p>This kind of idea is often applied in marketing and search. Suppose we know that a user is interested in site <span class="math inline">\(A\)</span>. Then, if that user searches for something online, we can use that information by computing a PageRank ranking and returning the top nodes, <em>using a biased teleportation vector</em>. This would allow us to balance the objectives of returning webpages that are relevant <em>overall</em> and webpages that are especially relevant <em>for that user</em>.</p>


<!-- -->

<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-brin1998anatomy" class="csl-entry" role="listitem">
Brin, Sergey, and Lawrence Page. 1998. <span>“The Anatomy of a Large-Scale Hypertextual Web Search Engine.”</span> <em>Computer Networks and ISDN Systems</em> 30 (1-7): 107–17.
</div>
</div>
</section>

<p><br> <br> <span style="color:grey;">© Heather Zinn Brooks and Phil Chodrow, 2025</span></p></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../chapters/41-link-prediction.html" class="pagination-link" aria-label="Link Prediction and Feedback Loops">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Link Prediction and Feedback Loops</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../chapters/51-agent-based-modeling.html" class="pagination-link" aria-label="Agent-Based Modeling on Networks">
        <span class="nav-page-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Agent-Based Modeling on Networks</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb7" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="an">code-fold:</span><span class="co"> true</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="an">code-summary:</span><span class="co"> "Show code"</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="an">jupyter:</span><span class="co"> python3</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="fu"># Random Walks</span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>*Open the live notebook in Google Colab [here](https://colab.research.google.com/github/network-science-notes/network-science-notes.github.io/blob/main/docs/live-notebooks/50-random-walks.ipynb).* </span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>Suppose that we have a very large network, and we'd like to explore it. Perhaps we don't even have access to all the edges. This is a common situation in data collection. A webscraper for gathering data, for example, doesn't have access to the entire network of webpages to be scraped; usually it has access to *one page at a time* and the links it contains. At each stage, the webscraper needs to follow a link in order to get the next piece of information. </span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>There are many ways to explore a network, but the most fundamental one is the *simple random walk*. We'll discuss the simple random walk, highlight some of its core properties, and connect it to some ideas that we've already seen. Then, we'll introduce the *teleporting random walk*, which is the foundation of the internet-changing PageRank algorithm originally used by Google. Finally, we'll take another look network navigation and the small-world phenomenon. </span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a><span class="fu">## The Simple Random Walk {#sec-srw}</span></span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>The simple random walk is easier to describe in English than it is to formulate mathematically. In intuitive terms, we imagine a walker who starts at some node $i$ in the graph. The walker then picks one of the neighbors $j$ of $i$ uniformly at random, and moves to $j$. Then, the walker picks one of the neighbors $k$ of $j$ uniformly at random, and moves to $k$, and so on. </span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>::: {.callout-note}</span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>::: {#def-simple-random-walk}</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a><span class="fu">## Simple Random Walk (SRW)</span></span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>A **simple random walk** on a graph $G$ with adjacency matrix $\mathbf{A}\in \mathbb{R}^{n\times n}$ is a countable sequence of random variables $X_1,\ldots,X_t,\ldots$ which take values in the node set $N$ of $G$. We have </span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a>\mathbb{P}(X_{t+1} = i | X_t = j_t, X_{t-1} = j_{t-1},\ldots,X_{1} = j_1) &amp;=  \mathbb{P}(X_{t+1} = i | X_t = j_t) <span class="sc">\\</span> </span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a>&amp;= \begin{cases}</span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a>        \frac{1}{k_j} &amp;\quad j \text{ is connected to } i <span class="sc">\\</span> </span>
<span id="cb7-30"><a href="#cb7-30" aria-hidden="true" tabindex="-1"></a>        0 &amp;\quad \text{otherwise.}</span>
<span id="cb7-31"><a href="#cb7-31" aria-hidden="true" tabindex="-1"></a>    \end{cases} <span class="sc">\\</span> </span>
<span id="cb7-32"><a href="#cb7-32" aria-hidden="true" tabindex="-1"></a>    &amp;= \frac{a_{ij}}{k_j}\;. </span>
<span id="cb7-33"><a href="#cb7-33" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb7-34"><a href="#cb7-34" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb7-35"><a href="#cb7-35" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb7-36"><a href="#cb7-36" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb7-37"><a href="#cb7-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-38"><a href="#cb7-38" aria-hidden="true" tabindex="-1"></a>In @def-simple-random-walk, the first equality is the *[Markov property](https://en.wikipedia.org/wiki/Markov_property)*: the future state of the random walk depends only on where it is right now (i.e. the value of $X_t$), not where it's been previously. The second and third equalities give mathematical structure to the idea of "picking a node connected to $j$ uniformly at random." </span>
<span id="cb7-39"><a href="#cb7-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-40"><a href="#cb7-40" aria-hidden="true" tabindex="-1"></a>::: {.callout-note}</span>
<span id="cb7-41"><a href="#cb7-41" aria-hidden="true" tabindex="-1"></a>::: {#def-transition-matrix}</span>
<span id="cb7-42"><a href="#cb7-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-43"><a href="#cb7-43" aria-hidden="true" tabindex="-1"></a><span class="fu">## Transition Matrix of a SRW</span></span>
<span id="cb7-44"><a href="#cb7-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-45"><a href="#cb7-45" aria-hidden="true" tabindex="-1"></a>The **transition matrix** of a simple random walk on a connected graph $G$ with adjacency matrix $\mathbf{A}$ is $\mathbf{P} = \mathbf{A}\mathbf{D}^{-1}$. Its entries are $p_{ij} = a_{ij}/k_j$, where $k_j$ is the degree of node $j$ and $\mathbf{D}$ is the diagonal matrix whose $jj$th entry is $k_j$. </span>
<span id="cb7-46"><a href="#cb7-46" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb7-47"><a href="#cb7-47" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb7-48"><a href="#cb7-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-49"><a href="#cb7-49" aria-hidden="true" tabindex="-1"></a>::: {.callout-caution}</span>
<span id="cb7-50"><a href="#cb7-50" aria-hidden="true" tabindex="-1"></a>***Exercise***: Let $p_{ij}$ denote the entries of $\mathbf{P}$. Check that </span>
<span id="cb7-51"><a href="#cb7-51" aria-hidden="true" tabindex="-1"></a>$\sum_{i \in N} p_{ij} = 1$, and interpret this fact. We say a matrix with this property is **(column) stochastic**.</span>
<span id="cb7-52"><a href="#cb7-52" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb7-53"><a href="#cb7-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-54"><a href="#cb7-54" aria-hidden="true" tabindex="-1"></a>::: {.hide .solution}</span>
<span id="cb7-55"><a href="#cb7-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-56"><a href="#cb7-56" aria-hidden="true" tabindex="-1"></a> As defined, $p_{ij} = \frac{a_{ij}}{k_j}$. Thus, $\sum_i p_{ij} = \sum_i \frac{a_{ij}}{k_j} = \frac{1}{k_j}\sum_i a_{ij} = \frac{k_j}{k_j} = 1$.</span>
<span id="cb7-57"><a href="#cb7-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-58"><a href="#cb7-58" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb7-59"><a href="#cb7-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-60"><a href="#cb7-60" aria-hidden="true" tabindex="-1"></a>What does the transition matrix do? Well, we can use the law of total probability to write: </span>
<span id="cb7-61"><a href="#cb7-61" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb7-62"><a href="#cb7-62" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb7-63"><a href="#cb7-63" aria-hidden="true" tabindex="-1"></a>\mathbb{P}(X_{t+1} = i) &amp;= \sum_{j \in N}\mathbb{P}(X_{t+1} = i|X_{t} = j)\mathbb{P}(X_t = j) <span class="sc">\\</span> </span>
<span id="cb7-64"><a href="#cb7-64" aria-hidden="true" tabindex="-1"></a>&amp;= \sum_{j \in N}p_{ij}\mathbb{P}(X_t = j)\;.</span>
<span id="cb7-65"><a href="#cb7-65" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb7-66"><a href="#cb7-66" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb7-67"><a href="#cb7-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-68"><a href="#cb7-68" aria-hidden="true" tabindex="-1"></a>Let $\mathbf{q}(t)$ be the vector with entries $q_i(t) = \mathbb{P}(X_{t} = i)$. We have just shown the most important relation in the study of random walks and their generalizations, Markov chains: </span>
<span id="cb7-69"><a href="#cb7-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-70"><a href="#cb7-70" aria-hidden="true" tabindex="-1"></a>:::{.callout-tip}</span>
<span id="cb7-71"><a href="#cb7-71" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb7-72"><a href="#cb7-72" aria-hidden="true" tabindex="-1"></a>\mathbf{q}(t+1) = \mathbf{P}\mathbf{q}(t)</span>
<span id="cb7-73"><a href="#cb7-73" aria-hidden="true" tabindex="-1"></a>$${#eq-transition}</span>
<span id="cb7-74"><a href="#cb7-74" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb7-75"><a href="#cb7-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-76"><a href="#cb7-76" aria-hidden="true" tabindex="-1"></a>@eq-transition has an immediate consequence: $\mathbf{q}(t) = \mathbf{P}^{t}\mathbf{q}(0)$. So, if we know the *initial distribution* $\mathbf{q}(0)$ describing the location at which the walker begins, we can get all other information we need from the matrix $\mathbf{P}$ and its powers. </span>
<span id="cb7-77"><a href="#cb7-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-78"><a href="#cb7-78" aria-hidden="true" tabindex="-1"></a><span class="fu">### Stationary Distribution: Existence and Uniqueness</span></span>
<span id="cb7-79"><a href="#cb7-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-80"><a href="#cb7-80" aria-hidden="true" tabindex="-1"></a>Throughout this section, we assume that the graph $G$ is connected. </span>
<span id="cb7-81"><a href="#cb7-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-82"><a href="#cb7-82" aria-hidden="true" tabindex="-1"></a>:::{.callout-note}</span>
<span id="cb7-83"><a href="#cb7-83" aria-hidden="true" tabindex="-1"></a>We say that an SRW has a *stationary distribution* $\pi \in \mathbb{R}^n$ if $\lim_{t\rightarrow \infty} \mathbf{q}(t) = \mathbf{\pi}$, *regardless of the initial distribution* $\mathbf{q}(0)$. </span>
<span id="cb7-84"><a href="#cb7-84" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb7-85"><a href="#cb7-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-86"><a href="#cb7-86" aria-hidden="true" tabindex="-1"></a>:::{.callout-note}</span>
<span id="cb7-87"><a href="#cb7-87" aria-hidden="true" tabindex="-1"></a>:::{#def-periodic}</span>
<span id="cb7-88"><a href="#cb7-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-89"><a href="#cb7-89" aria-hidden="true" tabindex="-1"></a>A graph is *aperiodic* if the greatest common divisor of lengths of its cycles is 1. A graph is *periodic* if it is not aperiodic. </span>
<span id="cb7-90"><a href="#cb7-90" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb7-91"><a href="#cb7-91" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb7-92"><a href="#cb7-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-93"><a href="#cb7-93" aria-hidden="true" tabindex="-1"></a>A simple example of a periodic graph is a $k$-cycle. </span>
<span id="cb7-94"><a href="#cb7-94" aria-hidden="true" tabindex="-1"></a>A less simple example is a *bipartite graph*, in which each node can be separated into one of two classes $S_1$ and $S_2$ such that nodes in $S_1$ only connect to nodes in $S_2$ (and not to any other nodes in $S_1$). </span>
<span id="cb7-95"><a href="#cb7-95" aria-hidden="true" tabindex="-1"></a>You can check that bipartiteness implies that every cycle has length divisible by 2, so the graph is periodic. </span>
<span id="cb7-96"><a href="#cb7-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-97"><a href="#cb7-97" aria-hidden="true" tabindex="-1"></a>:::{.callout-tip}</span>
<span id="cb7-98"><a href="#cb7-98" aria-hidden="true" tabindex="-1"></a>:::{#thm-stationary}</span>
<span id="cb7-99"><a href="#cb7-99" aria-hidden="true" tabindex="-1"></a>Suppose that $G$ is connected and aperiodic. Then, </span>
<span id="cb7-100"><a href="#cb7-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-101"><a href="#cb7-101" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$G$ has a stationary distribution $\pi$. </span>
<span id="cb7-102"><a href="#cb7-102" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>This stationary distribution is unique. </span>
<span id="cb7-103"><a href="#cb7-103" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The stationary distribution is the unique eigenvector of the transition matrix $\mathbf{P}$ with eigenvalue $1$. </span>
<span id="cb7-104"><a href="#cb7-104" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb7-105"><a href="#cb7-105" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb7-106"><a href="#cb7-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-107"><a href="#cb7-107" aria-hidden="true" tabindex="-1"></a>@thm-stationary is actually a theorem about discrete-time finite-state Markov chains in general, and its full proof is beyond the scope of this course. Here's a sketch:</span>
<span id="cb7-108"><a href="#cb7-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-109"><a href="#cb7-109" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>The condition that $G$ is connected implies that the matrix $\mathbf{P}$ is <span class="co">[</span><span class="ot">irreducible</span><span class="co">](https://en.wikipedia.org/wiki/Perron%E2%80%93Frobenius_theorem#Classification_of_matrices)</span>.</span>
<span id="cb7-110"><a href="#cb7-110" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>This allows us to apply the <span class="co">[</span><span class="ot">Perron-Frobenius theorem</span><span class="co">](https://en.wikipedia.org/wiki/Perron–Frobenius_theorem)</span> to conclude that $\mathbf{P}$ has a unique eigenvector with strictly positive entries, which we'll call ${\bf \pi}$. Since $\mathbf{P}$ is column stochastic, a direct calculation shows that the corresponding eigenvalue of ${\bf \pi}$ is 1, and we have $\pi = \mathbf{P}\pi$. </span>
<span id="cb7-111"><a href="#cb7-111" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>One further shows that $\lim_{t \rightarrow \infty}\mathbf{P}^t$ exists and that its rows become equal to the eigenvector $\pi$ (this is related to power iteration). </span>
<span id="cb7-112"><a href="#cb7-112" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>Because each row of limiting matrix describe the long-run behavior of the random walk from a given starting node, one infers that $\pi$ is indeed a stationary state. Because all the rows agree in the limit, one infers that $\pi$ is the only such stationary state. </span>
<span id="cb7-113"><a href="#cb7-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-114"><a href="#cb7-114" aria-hidden="true" tabindex="-1"></a><span class="fu">### Stationary Distribution: Structure</span></span>
<span id="cb7-115"><a href="#cb7-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-116"><a href="#cb7-116" aria-hidden="true" tabindex="-1"></a>We know from @thm-stationary that there is a unique stationary distribution for the simple random walk, and that this distribution describes, in the long-term, the amount of time that the walker spends on a node. What actually *is* the stationary distribution? For many Markov chains, including more complicated random walks, it can be difficult to describe the stationary distribution exactly. In this case the answer is surprisingly simple, although it's one of those things that's much easier to check than it is to find in the first place. </span>
<span id="cb7-117"><a href="#cb7-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-118"><a href="#cb7-118" aria-hidden="true" tabindex="-1"></a>:::{.callout-note}</span>
<span id="cb7-119"><a href="#cb7-119" aria-hidden="true" tabindex="-1"></a>:::{#thm-degree}</span>
<span id="cb7-120"><a href="#cb7-120" aria-hidden="true" tabindex="-1"></a><span class="fu">## Stationary Distribution of an SRW</span></span>
<span id="cb7-121"><a href="#cb7-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-122"><a href="#cb7-122" aria-hidden="true" tabindex="-1"></a>The stationary distribution of an SRW is $\pi = \frac{1}{2m}\mathbf{k}$, where $\mathbf{k}$ is the vector of node degrees. </span>
<span id="cb7-123"><a href="#cb7-123" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb7-124"><a href="#cb7-124" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb7-125"><a href="#cb7-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-126"><a href="#cb7-126" aria-hidden="true" tabindex="-1"></a>:::{.proof}</span>
<span id="cb7-127"><a href="#cb7-127" aria-hidden="true" tabindex="-1"></a>We can do a direct calculation:</span>
<span id="cb7-128"><a href="#cb7-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-129"><a href="#cb7-129" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb7-130"><a href="#cb7-130" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb7-131"><a href="#cb7-131" aria-hidden="true" tabindex="-1"></a>\mathbf{P}\pi = \mathbf{A}\mathbf{D}^{-1}\left(\frac{1}{2m}\mathbf{k}\right) = \frac{1}{2m}\mathbf{A}\mathbf{1} </span>
<span id="cb7-132"><a href="#cb7-132" aria-hidden="true" tabindex="-1"></a>= \frac{1}{2m}\mathbf{k}</span>
<span id="cb7-133"><a href="#cb7-133" aria-hidden="true" tabindex="-1"></a>= \pi\;. </span>
<span id="cb7-134"><a href="#cb7-134" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb7-135"><a href="#cb7-135" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb7-136"><a href="#cb7-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-137"><a href="#cb7-137" aria-hidden="true" tabindex="-1"></a>For the second equality we have used the quickly-checked identity $\mathbf{D}^{-1}\mathbf{k} = \mathbf{1}$, while for the third we have used the formula $\mathbf{k} = \mathbf{A}\mathbf{1}$. </span>
<span id="cb7-138"><a href="#cb7-138" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb7-139"><a href="#cb7-139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-140"><a href="#cb7-140" aria-hidden="true" tabindex="-1"></a>So, for simple random walks, $\mathbb{P}(X_t = i)$ when $t$ is large is approximately $k_i/2m$, proportional to the degree of node $i$. The intuition here is that the amount of time I spend in state is directly proportional to the number of ways that I can enter that state. </span>
<span id="cb7-141"><a href="#cb7-141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-142"><a href="#cb7-142" aria-hidden="true" tabindex="-1"></a><span class="fu">## Exploration and Ranking: PageRank</span></span>
<span id="cb7-143"><a href="#cb7-143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-144"><a href="#cb7-144" aria-hidden="true" tabindex="-1"></a>PageRank is the algorithm that originally made Google a dominant player in the domain of web search.<span class="co">[</span><span class="ot">@brin1998anatomy</span><span class="co">]</span>{.aside} The idea of PageRank is again to explore the graph using a random exploration process. The underlying process is closely related to the simple random walk that we described earlier. However, there are two important differences. </span>
<span id="cb7-145"><a href="#cb7-145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-146"><a href="#cb7-146" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>First, PageRank works on *directed* graphs. This matches the original application area; the web can be viewed as a *directed* network of links between pages. The reason directedness is so important is that, if $i \rightarrow j$ ($i$ links to $j$), it doesn't follow that $j\rightarrow i$. Capturing these kinds of asymmetric relationships is very important for reasonable ranking procedures. </span>
<span id="cb7-147"><a href="#cb7-147" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Unlike the SRW, PageRank is able to explore graphs that are non-ergodic. </span>
<span id="cb7-148"><a href="#cb7-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-149"><a href="#cb7-149" aria-hidden="true" tabindex="-1"></a>So, suppose we have a *directed* graph with adjacency matrix $\mathbf{A}$. The important thing to remember is that now $\mathbf{A}$ is not required to be symmetric. We interpret the entries of the adjacency matrix so that $a_{ij} = 1$ if $j \rightarrow i$. Since $\mathbf{A}$ need not be symmetric, $a_{ij} \neq a_{ji}$ in general. </span>
<span id="cb7-150"><a href="#cb7-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-151"><a href="#cb7-151" aria-hidden="true" tabindex="-1"></a>The definition of a random walk on a directed graph is very similar to the definition on an undirected graph. It is again a sequence of random variables with the Markov property; only the transition probabilities differ. </span>
<span id="cb7-152"><a href="#cb7-152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-153"><a href="#cb7-153" aria-hidden="true" tabindex="-1"></a>:::{.callout-note}</span>
<span id="cb7-154"><a href="#cb7-154" aria-hidden="true" tabindex="-1"></a>:::{#def-directed-SRW}</span>
<span id="cb7-155"><a href="#cb7-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-156"><a href="#cb7-156" aria-hidden="true" tabindex="-1"></a><span class="fu">## Simple Random Walk on a Directed Graph</span></span>
<span id="cb7-157"><a href="#cb7-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-158"><a href="#cb7-158" aria-hidden="true" tabindex="-1"></a>The SRW on a directed graph has transition probabilities </span>
<span id="cb7-159"><a href="#cb7-159" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb7-160"><a href="#cb7-160" aria-hidden="true" tabindex="-1"></a>\mathbb{P}(X_{t+1} = i | X_t = j) = \frac{a_{ij}}{k_j^{\mathrm{out}}}\;,</span>
<span id="cb7-161"><a href="#cb7-161" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb7-162"><a href="#cb7-162" aria-hidden="true" tabindex="-1"></a>where $k_j^{\mathrm{out}} = \sum_{i \in N}a_{ij}$ is the number of outgoing links from node $j$. The transition matrix of this walk is </span>
<span id="cb7-163"><a href="#cb7-163" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb7-164"><a href="#cb7-164" aria-hidden="true" tabindex="-1"></a>\mathbf{P} = \mathbf{A}(\mathbf{D}^{\mathrm{out}})^{-1}\;.</span>
<span id="cb7-165"><a href="#cb7-165" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb7-166"><a href="#cb7-166" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb7-167"><a href="#cb7-167" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb7-168"><a href="#cb7-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-169"><a href="#cb7-169" aria-hidden="true" tabindex="-1"></a>:::{.callout-caution}</span>
<span id="cb7-170"><a href="#cb7-170" aria-hidden="true" tabindex="-1"></a>Because $\mathbf{A}$ is not symmetric, we can also define $k_i^{\mathrm{in}} = \sum_{j \in N}a_{ij}$, the number of incoming links to node $j$. Importantly, $k_i^{\mathrm{in}} \neq k_i^{\mathrm{out}}$ in general. </span>
<span id="cb7-171"><a href="#cb7-171" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb7-172"><a href="#cb7-172" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-173"><a href="#cb7-173" aria-hidden="true" tabindex="-1"></a>Many of the same considerations from the undirected setting carry over to the directed setting. </span>
<span id="cb7-174"><a href="#cb7-174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-175"><a href="#cb7-175" aria-hidden="true" tabindex="-1"></a>:::{.callout-tip}</span>
<span id="cb7-176"><a href="#cb7-176" aria-hidden="true" tabindex="-1"></a>:::{#thm-stationary-directed}</span>
<span id="cb7-177"><a href="#cb7-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-178"><a href="#cb7-178" aria-hidden="true" tabindex="-1"></a><span class="fu">## Stationary Distributions of Directed Random Walks</span></span>
<span id="cb7-179"><a href="#cb7-179" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-180"><a href="#cb7-180" aria-hidden="true" tabindex="-1"></a>Suppose that:</span>
<span id="cb7-181"><a href="#cb7-181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-182"><a href="#cb7-182" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>There exists some integer power $t &gt; 0$ such that every entry of $\mathbf{A}^t$ is positive. </span>
<span id="cb7-183"><a href="#cb7-183" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>The greatest common divisor of the *directed* cycles in $G$ is 1. </span>
<span id="cb7-184"><a href="#cb7-184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-185"><a href="#cb7-185" aria-hidden="true" tabindex="-1"></a>Then, the SRW on $G$ has a stationary distribution $\pi$, which is a solution of the eigenproblem </span>
<span id="cb7-186"><a href="#cb7-186" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb7-187"><a href="#cb7-187" aria-hidden="true" tabindex="-1"></a>\pi = \mathbf{P}\pi\;.</span>
<span id="cb7-188"><a href="#cb7-188" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb7-189"><a href="#cb7-189" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb7-190"><a href="#cb7-190" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb7-191"><a href="#cb7-191" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-192"><a href="#cb7-192" aria-hidden="true" tabindex="-1"></a>Condition (1) in @thm-stationary-directed is essentially a connectedness condition: it says that there has to be a directed path from every node to every other node in the network. So, as you might reasonably expect, the directed random walk doesn't really overcome the need for the graph to be connected. This can be a problem for network exploration, as it's more common for directed networks to not be connected in this way.<span class="co">[</span><span class="ot">A bit more subtly, directed graphs that are *almost* disconnected are subject to *slow mixing* of the random walk, which implies very inefficient exploration of the network.</span><span class="co">]</span> PageRank overcomes this limitation by allowing the walker to randomly hop to new nodes, independent of the network structure. </span>
<span id="cb7-193"><a href="#cb7-193" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-194"><a href="#cb7-194" aria-hidden="true" tabindex="-1"></a>:::{.callout-note}</span>
<span id="cb7-195"><a href="#cb7-195" aria-hidden="true" tabindex="-1"></a>:::{#def-pagerank-walk}</span>
<span id="cb7-196"><a href="#cb7-196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-197"><a href="#cb7-197" aria-hidden="true" tabindex="-1"></a><span class="fu">## PageRank Random Walk</span></span>
<span id="cb7-198"><a href="#cb7-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-199"><a href="#cb7-199" aria-hidden="true" tabindex="-1"></a>The **PageRank random walk** has two parameters: </span>
<span id="cb7-200"><a href="#cb7-200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-201"><a href="#cb7-201" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The *teleportation vector* $\mathbf{v} \in \mathbb{R}^n_+$, which we assume to satisfy $\sum_{i\in N}v_i = 1$. </span>
<span id="cb7-202"><a href="#cb7-202" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The *teleportation rate* $\alpha\in <span class="co">[</span><span class="ot">0,1</span><span class="co">]</span>$. </span>
<span id="cb7-203"><a href="#cb7-203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-204"><a href="#cb7-204" aria-hidden="true" tabindex="-1"></a>This walk has transition probabilities </span>
<span id="cb7-205"><a href="#cb7-205" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb7-206"><a href="#cb7-206" aria-hidden="true" tabindex="-1"></a>\mathbb{P}(X_{t+1} = i|X_{t}=j) = (1-\alpha)\frac{a_{ij}}{k_j^{\mathrm{out}}} + \alpha v_i\;. </span>
<span id="cb7-207"><a href="#cb7-207" aria-hidden="true" tabindex="-1"></a>$${#eq-pagerank-transition}</span>
<span id="cb7-208"><a href="#cb7-208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-209"><a href="#cb7-209" aria-hidden="true" tabindex="-1"></a>Its transition matrix is </span>
<span id="cb7-210"><a href="#cb7-210" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-211"><a href="#cb7-211" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb7-212"><a href="#cb7-212" aria-hidden="true" tabindex="-1"></a>\mathbf{P} = (1-\alpha) \mathbf{A}(\mathbf{D}^{\mathrm{out}})^{-1} + \alpha \mathbf{V}\;,</span>
<span id="cb7-213"><a href="#cb7-213" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb7-214"><a href="#cb7-214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-215"><a href="#cb7-215" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb7-216"><a href="#cb7-216" aria-hidden="true" tabindex="-1"></a>\mathbf{V} = \left[\begin{matrix}</span>
<span id="cb7-217"><a href="#cb7-217" aria-hidden="true" tabindex="-1"></a>    | &amp; | &amp; \cdots &amp; | <span class="sc">\\</span> </span>
<span id="cb7-218"><a href="#cb7-218" aria-hidden="true" tabindex="-1"></a>    \mathbf{v} &amp; \mathbf{v} &amp; \cdots &amp; \mathbf{v} <span class="sc">\\</span> </span>
<span id="cb7-219"><a href="#cb7-219" aria-hidden="true" tabindex="-1"></a>    | &amp; | &amp; \cdots &amp; |</span>
<span id="cb7-220"><a href="#cb7-220" aria-hidden="true" tabindex="-1"></a>\end{matrix}\right]\;.</span>
<span id="cb7-221"><a href="#cb7-221" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb7-222"><a href="#cb7-222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-223"><a href="#cb7-223" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb7-224"><a href="#cb7-224" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb7-225"><a href="#cb7-225" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-226"><a href="#cb7-226" aria-hidden="true" tabindex="-1"></a>Here's the intuitive way to think about this walk. At each time step, the walker flips a weighted coin with probability of heads equal to $\alpha$. </span>
<span id="cb7-227"><a href="#cb7-227" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-228"><a href="#cb7-228" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>If heads, the walker chooses to sample from the probability distribution encoded by $\mathbf{v}$. That is, the walker chooses from among all the nodes in $N$, and picks node $i$ with probability $v_i$. </span>
<span id="cb7-229"><a href="#cb7-229" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>If tails, the walker instead follows a link, just like in the directed random walk. </span>
<span id="cb7-230"><a href="#cb7-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-231"><a href="#cb7-231" aria-hidden="true" tabindex="-1"></a>This is why there are two terms in the transition probability in @eq-pagerank-transition. The first term corresponds to the "tails" scenario in which the walker does a step corresponding to the directed random walk, while the second term corresponds to teleportation. </span>
<span id="cb7-232"><a href="#cb7-232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-233"><a href="#cb7-233" aria-hidden="true" tabindex="-1"></a>The standard choice of the teleportation vector is $\mathbf{v} = \frac{1}{n}\mathbf{1}$, so each node has an equal probability of being chosen for teleportation. However, it's also possible to take other approaches, as we'll see in a moment. </span>
<span id="cb7-234"><a href="#cb7-234" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-235"><a href="#cb7-235" aria-hidden="true" tabindex="-1"></a>:::{.callout-note}</span>
<span id="cb7-236"><a href="#cb7-236" aria-hidden="true" tabindex="-1"></a>:::{#thm-pagerank}</span>
<span id="cb7-237"><a href="#cb7-237" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-238"><a href="#cb7-238" aria-hidden="true" tabindex="-1"></a><span class="fu">## Stationary Distribution of PageRank</span></span>
<span id="cb7-239"><a href="#cb7-239" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-240"><a href="#cb7-240" aria-hidden="true" tabindex="-1"></a>Suppose that there exists an integer power $t$ such that $\mathbf{P}^t$ has all entries strictly positive. Then, the PageRank random walk has a unique stationary distribution, and this distribution may again be found by solving $\pi = \mathbf{P}\pi$. </span>
<span id="cb7-241"><a href="#cb7-241" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb7-242"><a href="#cb7-242" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb7-243"><a href="#cb7-243" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-244"><a href="#cb7-244" aria-hidden="true" tabindex="-1"></a>:::{.callout-caution}</span>
<span id="cb7-245"><a href="#cb7-245" aria-hidden="true" tabindex="-1"></a>**Exercise**: Show that, when $\mathbf{v} = \frac{1}{n}\mathbf{1}$, @thm-pagerank implies that the PageRank walk always has a stationary distribution, regardless of the graph. </span>
<span id="cb7-246"><a href="#cb7-246" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb7-247"><a href="#cb7-247" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-248"><a href="#cb7-248" aria-hidden="true" tabindex="-1"></a>:::{.callout-caution}</span>
<span id="cb7-249"><a href="#cb7-249" aria-hidden="true" tabindex="-1"></a>**Challenge**: Give a necessary and sufficient condition in terms of $\mathbf{A}$ and $\mathbf{v}$ for PageRank to have a stationary distribution. </span>
<span id="cb7-250"><a href="#cb7-250" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb7-251"><a href="#cb7-251" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-252"><a href="#cb7-252" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-253"><a href="#cb7-253" aria-hidden="true" tabindex="-1"></a><span class="fu">### Implementation</span></span>
<span id="cb7-254"><a href="#cb7-254" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-255"><a href="#cb7-255" aria-hidden="true" tabindex="-1"></a>Let's code up a quick example to visualize PageRank. We'll use the Hamilton Mentions graph: </span>
<span id="cb7-256"><a href="#cb7-256" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-259"><a href="#cb7-259" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb7-260"><a href="#cb7-260" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> networkx <span class="im">as</span> nx</span>
<span id="cb7-261"><a href="#cb7-261" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb7-262"><a href="#cb7-262" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb7-263"><a href="#cb7-263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-264"><a href="#cb7-264" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">"https://philchodrow.github.io/PIC16A/homework/HW3-hamilton-data.csv"</span>, </span>
<span id="cb7-265"><a href="#cb7-265" aria-hidden="true" tabindex="-1"></a>names <span class="op">=</span> [<span class="st">"mentioner"</span>, <span class="st">"mentioned"</span>])</span>
<span id="cb7-266"><a href="#cb7-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-267"><a href="#cb7-267" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df[df[<span class="st">"mentioner"</span>] <span class="op">!=</span> df[<span class="st">"mentioned"</span>]]</span>
<span id="cb7-268"><a href="#cb7-268" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-269"><a href="#cb7-269" aria-hidden="true" tabindex="-1"></a>G <span class="op">=</span> nx.from_pandas_edgelist(df, </span>
<span id="cb7-270"><a href="#cb7-270" aria-hidden="true" tabindex="-1"></a>                            source <span class="op">=</span> <span class="st">"mentioner"</span>, </span>
<span id="cb7-271"><a href="#cb7-271" aria-hidden="true" tabindex="-1"></a>                            target <span class="op">=</span> <span class="st">"mentioned"</span>, </span>
<span id="cb7-272"><a href="#cb7-272" aria-hidden="true" tabindex="-1"></a>                            edge_attr<span class="op">=</span><span class="va">None</span>, </span>
<span id="cb7-273"><a href="#cb7-273" aria-hidden="true" tabindex="-1"></a>                            create_using<span class="op">=</span>nx.DiGraph())</span>
<span id="cb7-274"><a href="#cb7-274" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb7-275"><a href="#cb7-275" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-276"><a href="#cb7-276" aria-hidden="true" tabindex="-1"></a>There are a few nodes in this network with no outgoing edges. while there are modifications we can make to handle this kind of case, we can also just remove them from the graph. </span>
<span id="cb7-277"><a href="#cb7-277" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-280"><a href="#cb7-280" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb7-281"><a href="#cb7-281" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">2</span>):</span>
<span id="cb7-282"><a href="#cb7-282" aria-hidden="true" tabindex="-1"></a>    G <span class="op">=</span> G.subgraph([name <span class="cf">for</span> name, val <span class="kw">in</span> G.out_degree() <span class="cf">if</span> val <span class="op">&gt;</span> <span class="dv">0</span>])</span>
<span id="cb7-283"><a href="#cb7-283" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb7-284"><a href="#cb7-284" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-285"><a href="#cb7-285" aria-hidden="true" tabindex="-1"></a>Now we can write our PageRank function. We'll compute the transition matrix $\mathbf{P}$ and find its leading eigenvector. </span>
<span id="cb7-286"><a href="#cb7-286" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-289"><a href="#cb7-289" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb7-290"><a href="#cb7-290" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> pagerank(G, v, alpha <span class="op">=</span> <span class="fl">0.15</span>):</span>
<span id="cb7-291"><a href="#cb7-291" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-292"><a href="#cb7-292" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span> np.isclose(v.<span class="bu">sum</span>(), <span class="fl">1.0</span>)</span>
<span id="cb7-293"><a href="#cb7-293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-294"><a href="#cb7-294" aria-hidden="true" tabindex="-1"></a>    <span class="co"># construct the PR transition matrix</span></span>
<span id="cb7-295"><a href="#cb7-295" aria-hidden="true" tabindex="-1"></a>    A  <span class="op">=</span> nx.to_numpy_array(G).T</span>
<span id="cb7-296"><a href="#cb7-296" aria-hidden="true" tabindex="-1"></a>    K  <span class="op">=</span> np.diag(A.<span class="bu">sum</span>(axis <span class="op">=</span> <span class="dv">0</span>))     <span class="co"># K^out</span></span>
<span id="cb7-297"><a href="#cb7-297" aria-hidden="true" tabindex="-1"></a>    P_ <span class="op">=</span> A<span class="op">@</span>np.linalg.inv(K)           <span class="co"># random walk matrix</span></span>
<span id="cb7-298"><a href="#cb7-298" aria-hidden="true" tabindex="-1"></a>    V  <span class="op">=</span> np.outer(v, np.ones(<span class="bu">len</span>(v))) <span class="co"># teleportation matrix</span></span>
<span id="cb7-299"><a href="#cb7-299" aria-hidden="true" tabindex="-1"></a>    P <span class="op">=</span> (<span class="dv">1</span><span class="op">-</span>alpha)<span class="op">*</span>P_ <span class="op">+</span> alpha<span class="op">*</span>V        <span class="co"># overall transition matrix</span></span>
<span id="cb7-300"><a href="#cb7-300" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-301"><a href="#cb7-301" aria-hidden="true" tabindex="-1"></a>    <span class="co"># grab the eigenvector with eigenvalue 1, normalize it and return. </span></span>
<span id="cb7-302"><a href="#cb7-302" aria-hidden="true" tabindex="-1"></a>    eigs <span class="op">=</span> np.linalg.eig(P)        </span>
<span id="cb7-303"><a href="#cb7-303" aria-hidden="true" tabindex="-1"></a>    pi <span class="op">=</span> eigs[<span class="dv">1</span>][:,np.isclose(eigs[<span class="dv">0</span>], <span class="fl">1.0</span>)]</span>
<span id="cb7-304"><a href="#cb7-304" aria-hidden="true" tabindex="-1"></a>    pi <span class="op">=</span> np.<span class="bu">abs</span>(pi) <span class="op">/</span> np.<span class="bu">abs</span>(pi).<span class="bu">sum</span>()</span>
<span id="cb7-305"><a href="#cb7-305" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> pi</span>
<span id="cb7-306"><a href="#cb7-306" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb7-307"><a href="#cb7-307" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-310"><a href="#cb7-310" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb7-311"><a href="#cb7-311" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> draw_pagerank(G, v,  layout, alpha <span class="op">=</span> <span class="fl">0.15</span>):</span>
<span id="cb7-312"><a href="#cb7-312" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-313"><a href="#cb7-313" aria-hidden="true" tabindex="-1"></a>    pi <span class="op">=</span> pagerank(G, v, alpha <span class="op">=</span> alpha)</span>
<span id="cb7-314"><a href="#cb7-314" aria-hidden="true" tabindex="-1"></a>    nx.draw(G, layout, </span>
<span id="cb7-315"><a href="#cb7-315" aria-hidden="true" tabindex="-1"></a>            node_size <span class="op">=</span> <span class="dv">5000</span><span class="op">*</span>pi, </span>
<span id="cb7-316"><a href="#cb7-316" aria-hidden="true" tabindex="-1"></a>            with_labels <span class="op">=</span> <span class="va">True</span>,</span>
<span id="cb7-317"><a href="#cb7-317" aria-hidden="true" tabindex="-1"></a>            edge_color <span class="op">=</span> <span class="st">"lightgray"</span>, </span>
<span id="cb7-318"><a href="#cb7-318" aria-hidden="true" tabindex="-1"></a>            node_color <span class="op">=</span> <span class="st">"lavender"</span>,</span>
<span id="cb7-319"><a href="#cb7-319" aria-hidden="true" tabindex="-1"></a>            edgecolors  <span class="op">=</span> <span class="st">"darkgray"</span>)</span>
<span id="cb7-320"><a href="#cb7-320" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-321"><a href="#cb7-321" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb7-322"><a href="#cb7-322" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-323"><a href="#cb7-323" aria-hidden="true" tabindex="-1"></a>Now we can visualize the PageRank stationary distribution for different choices of the teleportation vector $\mathbf{v}$ and the teleportation rate $\alpha$: </span>
<span id="cb7-324"><a href="#cb7-324" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-327"><a href="#cb7-327" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb7-328"><a href="#cb7-328" aria-hidden="true" tabindex="-1"></a>layout <span class="op">=</span> nx.fruchterman_reingold_layout(G)</span>
<span id="cb7-329"><a href="#cb7-329" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-330"><a href="#cb7-330" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="bu">len</span>(G.nodes())</span>
<span id="cb7-331"><a href="#cb7-331" aria-hidden="true" tabindex="-1"></a>v <span class="op">=</span> <span class="dv">1</span><span class="op">/</span>n<span class="op">*</span>np.ones(n)</span>
<span id="cb7-332"><a href="#cb7-332" aria-hidden="true" tabindex="-1"></a>draw_pagerank(G, v, layout, alpha <span class="op">=</span> <span class="fl">0.1</span>)</span>
<span id="cb7-333"><a href="#cb7-333" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb7-334"><a href="#cb7-334" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-335"><a href="#cb7-335" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-336"><a href="#cb7-336" aria-hidden="true" tabindex="-1"></a><span class="fu">## Seeded PageRank</span></span>
<span id="cb7-337"><a href="#cb7-337" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-338"><a href="#cb7-338" aria-hidden="true" tabindex="-1"></a>A useful feature of the way we've defined PageRank is that we can choose different teleportation vectors $\mathbf{v}$ in order to explore different parts of the graph. For example, suppose that we are especially interested in the part of the network surrouding certain characters. We can just change the teleportation vector $\mathbf{v}$ to highlight those specific characters. This approach is often called "personalized" or "seeded" PageRank. </span>
<span id="cb7-339"><a href="#cb7-339" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-342"><a href="#cb7-342" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb7-343"><a href="#cb7-343" aria-hidden="true" tabindex="-1"></a>v <span class="op">=</span> np.array([<span class="dv">1</span> <span class="cf">if</span> i <span class="op">==</span> <span class="st">"kingGeorge"</span> <span class="cf">else</span> <span class="dv">0</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">list</span>(G.nodes())])</span>
<span id="cb7-344"><a href="#cb7-344" aria-hidden="true" tabindex="-1"></a>draw_pagerank(G, v, layout, alpha <span class="op">=</span> <span class="fl">0.1</span>)</span>
<span id="cb7-345"><a href="#cb7-345" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb7-346"><a href="#cb7-346" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-347"><a href="#cb7-347" aria-hidden="true" tabindex="-1"></a>This time, we've highlighted the node corresponding to the character King George. Whereas when using the "basic" version of PageRank Hamilton, Burr, Washington, and Jefferson are all very important characters, in the personalized versio, Washington emerges as clearly the most important. </span>
<span id="cb7-348"><a href="#cb7-348" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-349"><a href="#cb7-349" aria-hidden="true" tabindex="-1"></a>This kind of idea is often applied in marketing and search. Suppose we know that a user is interested in site $A$. Then, if that user searches for something online, we can use that information by computing a PageRank ranking and returning the top nodes, *using a biased teleportation vector*. This would allow us to balance the objectives of returning webpages that are relevant *overall* and webpages that are especially relevant *for that user*.</span>
<span id="cb7-350"><a href="#cb7-350" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-351"><a href="#cb7-351" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-352"><a href="#cb7-352" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-353"><a href="#cb7-353" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-354"><a href="#cb7-354" aria-hidden="true" tabindex="-1"></a></span>
</code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->




</body></html>